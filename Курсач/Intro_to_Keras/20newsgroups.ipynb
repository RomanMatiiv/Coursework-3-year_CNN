{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habrahabr.ru/company/ods/blog/325432/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input,Dense,Activation,Dropout,BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words=1000 #Ограничение на кол-во слов\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(newsgroups_train[\"data\"])  # теперь токенизатор знает словарь для этого корпуса текстов\n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(newsgroups_train[\"data\"], mode='binary')\n",
    "x_test = tokenizer.texts_to_matrix(newsgroups_test[\"data\"], mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11314, 1000), (7532, 1000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Кодирование целевой переменной OHE для того чтобы передать кросс энтропии\n",
    "num_classes=np.unique(newsgroups_train[\"target\"]).shape[0]\n",
    "\n",
    "y_train = to_categorical(newsgroups_train[\"target\"], num_classes)\n",
    "y_test = to_categorical(newsgroups_test[\"target\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11314, 20), (7532, 20))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели (архитектуры)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input->Dense[512]->ReLu->Dropout->Dense[20]->Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Input(shape=(max_words,)) #(кол-во признаков,кол-во примеров(заранее не знаем))\n",
    "b = Dense(512)(a) #512 нейронов в полносвязном слое\n",
    "b = Activation('relu')(b) #ReLu активационная функция\n",
    "b = Dropout(0.5)(b) #Dropout слой с p=0.5\n",
    "b = Dense(num_classes)(b) #FC кол-во нейронов=кол-во классов (output-вероятность)\n",
    "b = Activation('softmax')(b) #Softmax активационная функция\n",
    "\n",
    "#Собираем все во едино\n",
    "model = Model(inputs=a, outputs=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"458pt\" viewBox=\"0.00 0.00 298.24 458.00\" width=\"298pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 454)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-454 294.2383,-454 294.2383,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4810467592 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4810467592</title>\n",
       "<polygon fill=\"none\" points=\"7.7793,-405.5 7.7793,-449.5 282.459,-449.5 282.459,-405.5 7.7793,-405.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.9604\" y=\"-423.3\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"136.1416,-405.5 136.1416,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.9761\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"136.1416,-427.5 191.8105,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.9761\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191.8105,-405.5 191.8105,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.1348\" y=\"-434.3\">(None, 1000)</text>\n",
       "<polyline fill=\"none\" points=\"191.8105,-427.5 282.459,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.1348\" y=\"-412.3\">(None, 1000)</text>\n",
       "</g>\n",
       "<!-- 4810465520 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4810465520</title>\n",
       "<polygon fill=\"none\" points=\"19.8345,-324.5 19.8345,-368.5 270.4038,-368.5 270.4038,-324.5 19.8345,-324.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.9604\" y=\"-342.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"124.0864,-324.5 124.0864,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151.9209\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"124.0864,-346.5 179.7554,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151.9209\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"179.7554,-324.5 179.7554,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.0796\" y=\"-353.3\">(None, 1000)</text>\n",
       "<polyline fill=\"none\" points=\"179.7554,-346.5 270.4038,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.0796\" y=\"-331.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 4810467592&#45;&gt;4810465520 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4810467592-&gt;4810465520</title>\n",
       "<path d=\"M145.1191,-405.3664C145.1191,-397.1516 145.1191,-387.6579 145.1191,-378.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"148.6192,-378.6068 145.1191,-368.6068 141.6192,-378.6069 148.6192,-378.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4809457168 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4809457168</title>\n",
       "<polygon fill=\"none\" points=\"0,-243.5 0,-287.5 290.2383,-287.5 290.2383,-243.5 0,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.4604\" y=\"-261.3\">activation_1: Activation</text>\n",
       "<polyline fill=\"none\" points=\"150.9209,-243.5 150.9209,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.7554\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"150.9209,-265.5 206.5898,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.7554\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"206.5898,-243.5 206.5898,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.4141\" y=\"-272.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"206.5898,-265.5 290.2383,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.4141\" y=\"-250.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 4810465520&#45;&gt;4809457168 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4810465520-&gt;4809457168</title>\n",
       "<path d=\"M145.1191,-324.3664C145.1191,-316.1516 145.1191,-306.6579 145.1191,-297.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"148.6192,-297.6068 145.1191,-287.6068 141.6192,-297.6069 148.6192,-297.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4810518600 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4810518600</title>\n",
       "<polygon fill=\"none\" points=\"11.6587,-162.5 11.6587,-206.5 278.5796,-206.5 278.5796,-162.5 11.6587,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.4604\" y=\"-180.3\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"139.2622,-162.5 139.2622,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.0967\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"139.2622,-184.5 194.9312,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.0967\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"194.9312,-162.5 194.9312,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.7554\" y=\"-191.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"194.9312,-184.5 278.5796,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.7554\" y=\"-169.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 4809457168&#45;&gt;4810518600 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4809457168-&gt;4810518600</title>\n",
       "<path d=\"M145.1191,-243.3664C145.1191,-235.1516 145.1191,-225.6579 145.1191,-216.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"148.6192,-216.6068 145.1191,-206.6068 141.6192,-216.6069 148.6192,-216.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4809455152 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4809455152</title>\n",
       "<polygon fill=\"none\" points=\"23.3345,-81.5 23.3345,-125.5 266.9038,-125.5 266.9038,-81.5 23.3345,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.4604\" y=\"-99.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"127.5864,-81.5 127.5864,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.4209\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"127.5864,-103.5 183.2554,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.4209\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"183.2554,-81.5 183.2554,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.0796\" y=\"-110.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"183.2554,-103.5 266.9038,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.0796\" y=\"-88.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 4810518600&#45;&gt;4809455152 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4810518600-&gt;4809455152</title>\n",
       "<path d=\"M145.1191,-162.3664C145.1191,-154.1516 145.1191,-144.6579 145.1191,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"148.6192,-135.6068 145.1191,-125.6068 141.6192,-135.6069 148.6192,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4470000664 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4470000664</title>\n",
       "<polygon fill=\"none\" points=\"3.5,-.5 3.5,-44.5 286.7383,-44.5 286.7383,-.5 3.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78.9604\" y=\"-18.3\">activation_2: Activation</text>\n",
       "<polyline fill=\"none\" points=\"154.4209,-.5 154.4209,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.2554\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"154.4209,-22.5 210.0898,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.2554\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"210.0898,-.5 210.0898,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.4141\" y=\"-29.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"210.0898,-22.5 286.7383,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.4141\" y=\"-7.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 4809455152&#45;&gt;4470000664 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4809455152-&gt;4470000664</title>\n",
       "<path d=\"M145.1191,-81.3664C145.1191,-73.1516 145.1191,-63.6579 145.1191,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"148.6192,-54.6068 145.1191,-44.6068 141.6192,-54.6069 148.6192,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Без ранней остановки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/50\n",
      "10182/10182 [==============================] - 2s 167us/step - loss: 0.0160 - acc: 0.9973 - val_loss: 1.0470 - val_acc: 0.7924\n",
      "Epoch 2/50\n",
      "10182/10182 [==============================] - 2s 165us/step - loss: 0.0114 - acc: 0.9978 - val_loss: 1.1021 - val_acc: 0.7898\n",
      "Epoch 3/50\n",
      "10182/10182 [==============================] - 2s 163us/step - loss: 0.0124 - acc: 0.9978 - val_loss: 1.0921 - val_acc: 0.7951\n",
      "Epoch 4/50\n",
      "10182/10182 [==============================] - 2s 163us/step - loss: 0.0143 - acc: 0.9972 - val_loss: 1.1032 - val_acc: 0.7889\n",
      "Epoch 5/50\n",
      "10182/10182 [==============================] - 2s 164us/step - loss: 0.0119 - acc: 0.9978 - val_loss: 1.0858 - val_acc: 0.7942\n",
      "Epoch 6/50\n",
      "10182/10182 [==============================] - 2s 165us/step - loss: 0.0147 - acc: 0.9968 - val_loss: 1.0775 - val_acc: 0.7889\n",
      "Epoch 7/50\n",
      "10182/10182 [==============================] - 2s 165us/step - loss: 0.0140 - acc: 0.9970 - val_loss: 1.0864 - val_acc: 0.7942\n",
      "Epoch 8/50\n",
      "10182/10182 [==============================] - 2s 168us/step - loss: 0.0203 - acc: 0.9948 - val_loss: 1.1615 - val_acc: 0.7827\n",
      "Epoch 9/50\n",
      "10182/10182 [==============================] - 2s 166us/step - loss: 0.0249 - acc: 0.9936 - val_loss: 1.1189 - val_acc: 0.7862\n",
      "Epoch 10/50\n",
      "10182/10182 [==============================] - 2s 183us/step - loss: 0.0194 - acc: 0.9954 - val_loss: 1.1436 - val_acc: 0.7853\n",
      "Epoch 11/50\n",
      "10182/10182 [==============================] - 2s 176us/step - loss: 0.0152 - acc: 0.9965 - val_loss: 1.1339 - val_acc: 0.7827\n",
      "Epoch 12/50\n",
      "10182/10182 [==============================] - 2s 191us/step - loss: 0.0159 - acc: 0.9961 - val_loss: 1.1814 - val_acc: 0.7809\n",
      "Epoch 13/50\n",
      "10182/10182 [==============================] - 2s 193us/step - loss: 0.0288 - acc: 0.9918 - val_loss: 1.1624 - val_acc: 0.7792\n",
      "Epoch 14/50\n",
      "10182/10182 [==============================] - 2s 187us/step - loss: 0.0200 - acc: 0.9952 - val_loss: 1.1620 - val_acc: 0.7871\n",
      "Epoch 15/50\n",
      "10182/10182 [==============================] - 2s 173us/step - loss: 0.0140 - acc: 0.9970 - val_loss: 1.1591 - val_acc: 0.7889\n",
      "Epoch 16/50\n",
      "10182/10182 [==============================] - 2s 174us/step - loss: 0.0136 - acc: 0.9977 - val_loss: 1.1730 - val_acc: 0.7871\n",
      "Epoch 17/50\n",
      "10182/10182 [==============================] - 2s 175us/step - loss: 0.0115 - acc: 0.9973 - val_loss: 1.1342 - val_acc: 0.7906\n",
      "Epoch 18/50\n",
      "10182/10182 [==============================] - 2s 173us/step - loss: 0.0096 - acc: 0.9974 - val_loss: 1.1628 - val_acc: 0.7898\n",
      "Epoch 19/50\n",
      "10182/10182 [==============================] - 2s 173us/step - loss: 0.0090 - acc: 0.9980 - val_loss: 1.1739 - val_acc: 0.7933\n",
      "Epoch 20/50\n",
      "10182/10182 [==============================] - 2s 173us/step - loss: 0.0098 - acc: 0.9977 - val_loss: 1.1597 - val_acc: 0.7871\n",
      "Epoch 21/50\n",
      "10182/10182 [==============================] - 2s 176us/step - loss: 0.0103 - acc: 0.9976 - val_loss: 1.1698 - val_acc: 0.7924\n",
      "Epoch 22/50\n",
      "10182/10182 [==============================] - 2s 199us/step - loss: 0.0155 - acc: 0.9968 - val_loss: 1.1642 - val_acc: 0.7915\n",
      "Epoch 23/50\n",
      "10182/10182 [==============================] - 2s 194us/step - loss: 0.0106 - acc: 0.9972 - val_loss: 1.1816 - val_acc: 0.7915\n",
      "Epoch 24/50\n",
      "10182/10182 [==============================] - 2s 193us/step - loss: 0.0080 - acc: 0.9986 - val_loss: 1.1640 - val_acc: 0.7880\n",
      "Epoch 25/50\n",
      "10182/10182 [==============================] - 2s 164us/step - loss: 0.0074 - acc: 0.9980 - val_loss: 1.1907 - val_acc: 0.7906\n",
      "Epoch 26/50\n",
      "10182/10182 [==============================] - 2s 165us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 1.1564 - val_acc: 0.7924\n",
      "Epoch 27/50\n",
      "10182/10182 [==============================] - 2s 194us/step - loss: 0.0117 - acc: 0.9972 - val_loss: 1.2308 - val_acc: 0.7765\n",
      "Epoch 28/50\n",
      "10182/10182 [==============================] - 2s 172us/step - loss: 0.0131 - acc: 0.9967 - val_loss: 1.1844 - val_acc: 0.8004\n",
      "Epoch 29/50\n",
      "10182/10182 [==============================] - 2s 160us/step - loss: 0.0102 - acc: 0.9975 - val_loss: 1.2180 - val_acc: 0.7942\n",
      "Epoch 30/50\n",
      "10182/10182 [==============================] - 2s 160us/step - loss: 0.0103 - acc: 0.9971 - val_loss: 1.2363 - val_acc: 0.7871\n",
      "Epoch 31/50\n",
      "10182/10182 [==============================] - 2s 160us/step - loss: 0.0129 - acc: 0.9970 - val_loss: 1.2320 - val_acc: 0.7924\n",
      "Epoch 32/50\n",
      "10182/10182 [==============================] - 2s 162us/step - loss: 0.0110 - acc: 0.9972 - val_loss: 1.2232 - val_acc: 0.7906\n",
      "Epoch 33/50\n",
      "10182/10182 [==============================] - 2s 178us/step - loss: 0.0080 - acc: 0.9980 - val_loss: 1.2844 - val_acc: 0.7977\n",
      "Epoch 34/50\n",
      "10182/10182 [==============================] - 2s 187us/step - loss: 0.0102 - acc: 0.9979 - val_loss: 1.2604 - val_acc: 0.7933\n",
      "Epoch 35/50\n",
      "10182/10182 [==============================] - 2s 202us/step - loss: 0.0117 - acc: 0.9966 - val_loss: 1.3013 - val_acc: 0.7853\n",
      "Epoch 36/50\n",
      "10182/10182 [==============================] - 2s 192us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 1.2376 - val_acc: 0.8048\n",
      "Epoch 37/50\n",
      "10182/10182 [==============================] - 2s 180us/step - loss: 0.0091 - acc: 0.9982 - val_loss: 1.2432 - val_acc: 0.7880\n",
      "Epoch 38/50\n",
      "10182/10182 [==============================] - 2s 180us/step - loss: 0.0097 - acc: 0.9977 - val_loss: 1.2173 - val_acc: 0.8030\n",
      "Epoch 39/50\n",
      "10182/10182 [==============================] - 2s 183us/step - loss: 0.0134 - acc: 0.9965 - val_loss: 1.2420 - val_acc: 0.7898\n",
      "Epoch 40/50\n",
      "10182/10182 [==============================] - 2s 177us/step - loss: 0.0141 - acc: 0.9959 - val_loss: 1.2176 - val_acc: 0.7986\n",
      "Epoch 41/50\n",
      "10182/10182 [==============================] - 2s 175us/step - loss: 0.0125 - acc: 0.9966 - val_loss: 1.2199 - val_acc: 0.7853\n",
      "Epoch 42/50\n",
      "10182/10182 [==============================] - 2s 164us/step - loss: 0.0089 - acc: 0.9978 - val_loss: 1.2728 - val_acc: 0.7906\n",
      "Epoch 43/50\n",
      "10182/10182 [==============================] - 2s 163us/step - loss: 0.0072 - acc: 0.9982 - val_loss: 1.2679 - val_acc: 0.7853\n",
      "Epoch 44/50\n",
      "10182/10182 [==============================] - 2s 162us/step - loss: 0.0099 - acc: 0.9980 - val_loss: 1.2869 - val_acc: 0.7836\n",
      "Epoch 45/50\n",
      "10182/10182 [==============================] - 2s 168us/step - loss: 0.0073 - acc: 0.9978 - val_loss: 1.3192 - val_acc: 0.7862\n",
      "Epoch 46/50\n",
      "10182/10182 [==============================] - 2s 173us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 1.2952 - val_acc: 0.7924\n",
      "Epoch 47/50\n",
      "10182/10182 [==============================] - 2s 171us/step - loss: 0.0057 - acc: 0.9990 - val_loss: 1.2888 - val_acc: 0.7959\n",
      "Epoch 48/50\n",
      "10182/10182 [==============================] - 2s 167us/step - loss: 0.0052 - acc: 0.9988 - val_loss: 1.2902 - val_acc: 0.7924\n",
      "Epoch 49/50\n",
      "10182/10182 [==============================] - 2s 170us/step - loss: 0.0054 - acc: 0.9989 - val_loss: 1.3307 - val_acc: 0.7968\n",
      "Epoch 50/50\n",
      "10182/10182 [==============================] - 2s 167us/step - loss: 0.0084 - acc: 0.9975 - val_loss: 1.3220 - val_acc: 0.7933\n",
      "CPU times: user 3min 44s, sys: 21 s, total: 4min 5s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size=100 #100 объектов на 1 эпоху а не вся обучающая выборка\n",
    "epochs=50      #кол-во эпох (сколько раз 100 объектов будут поданы сети)\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532/7532 [==============================] - 0s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.518675964814326, 0.6456452532455254]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Точность на отложенной выборке\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С ранней остоновкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/50\n",
      "10182/10182 [==============================] - 2s 170us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 1.3111 - val_acc: 0.7986\n",
      "Epoch 2/50\n",
      " 1200/10182 [==>...........................] - ETA: 1s - loss: 0.0057 - acc: 0.9983  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:526: RuntimeWarning: Early stopping conditioned on metric `value_loss` which is not available. Available metrics are: val_loss,val_acc,loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10182/10182 [==============================] - 2s 177us/step - loss: 0.0073 - acc: 0.9982 - val_loss: 1.3450 - val_acc: 0.7924\n",
      "Epoch 3/50\n",
      "10182/10182 [==============================] - 2s 169us/step - loss: 0.0083 - acc: 0.9980 - val_loss: 1.3169 - val_acc: 0.7933\n",
      "Epoch 4/50\n",
      "10182/10182 [==============================] - 2s 186us/step - loss: 0.0081 - acc: 0.9980 - val_loss: 1.2848 - val_acc: 0.7959\n",
      "Epoch 5/50\n",
      "10182/10182 [==============================] - 2s 184us/step - loss: 0.0060 - acc: 0.9983 - val_loss: 1.3029 - val_acc: 0.7959\n",
      "Epoch 6/50\n",
      "10182/10182 [==============================] - 2s 194us/step - loss: 0.0075 - acc: 0.9981 - val_loss: 1.2977 - val_acc: 0.7959\n",
      "Epoch 7/50\n",
      "10182/10182 [==============================] - 2s 177us/step - loss: 0.0063 - acc: 0.9988 - val_loss: 1.3423 - val_acc: 0.7906\n",
      "Epoch 8/50\n",
      "10182/10182 [==============================] - 2s 175us/step - loss: 0.0062 - acc: 0.9986 - val_loss: 1.3684 - val_acc: 0.7924\n",
      "Epoch 9/50\n",
      "10182/10182 [==============================] - 2s 190us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 1.3349 - val_acc: 0.7959\n",
      "Epoch 10/50\n",
      "10182/10182 [==============================] - 2s 175us/step - loss: 0.0097 - acc: 0.9983 - val_loss: 1.3430 - val_acc: 0.8012\n",
      "Epoch 11/50\n",
      "10182/10182 [==============================] - 2s 198us/step - loss: 0.0078 - acc: 0.9982 - val_loss: 1.3518 - val_acc: 0.8039\n",
      "Epoch 12/50\n",
      "10182/10182 [==============================] - 2s 184us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 1.3858 - val_acc: 0.7977\n",
      "Epoch 13/50\n",
      "10182/10182 [==============================] - 2s 174us/step - loss: 0.0132 - acc: 0.9967 - val_loss: 1.3681 - val_acc: 0.7906\n",
      "Epoch 14/50\n",
      "10182/10182 [==============================] - 2s 168us/step - loss: 0.0115 - acc: 0.9966 - val_loss: 1.3828 - val_acc: 0.7836\n",
      "Epoch 15/50\n",
      "10182/10182 [==============================] - 2s 175us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 1.3466 - val_acc: 0.7959\n",
      "Epoch 16/50\n",
      "10182/10182 [==============================] - 2s 172us/step - loss: 0.0069 - acc: 0.9981 - val_loss: 1.3407 - val_acc: 0.7951\n",
      "Epoch 17/50\n",
      "10182/10182 [==============================] - 2s 180us/step - loss: 0.0080 - acc: 0.9977 - val_loss: 1.3612 - val_acc: 0.7942\n",
      "Epoch 18/50\n",
      "10182/10182 [==============================] - 2s 169us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 1.3356 - val_acc: 0.7951\n",
      "Epoch 19/50\n",
      "10182/10182 [==============================] - 2s 163us/step - loss: 0.0057 - acc: 0.9987 - val_loss: 1.3433 - val_acc: 0.7986\n",
      "Epoch 20/50\n",
      "10182/10182 [==============================] - 2s 173us/step - loss: 0.0077 - acc: 0.9973 - val_loss: 1.3535 - val_acc: 0.7986\n",
      "Epoch 21/50\n",
      "10182/10182 [==============================] - 2s 167us/step - loss: 0.0095 - acc: 0.9976 - val_loss: 1.3375 - val_acc: 0.7924\n",
      "Epoch 22/50\n",
      "10182/10182 [==============================] - 2s 161us/step - loss: 0.0145 - acc: 0.9964 - val_loss: 1.3597 - val_acc: 0.7862\n",
      "Epoch 23/50\n",
      "10182/10182 [==============================] - 2s 174us/step - loss: 0.0103 - acc: 0.9970 - val_loss: 1.3882 - val_acc: 0.7898\n",
      "Epoch 24/50\n",
      "10182/10182 [==============================] - 2s 167us/step - loss: 0.0087 - acc: 0.9979 - val_loss: 1.3514 - val_acc: 0.7968\n",
      "Epoch 25/50\n",
      "10182/10182 [==============================] - 2s 165us/step - loss: 0.0081 - acc: 0.9978 - val_loss: 1.3676 - val_acc: 0.7915\n",
      "Epoch 26/50\n",
      "10182/10182 [==============================] - 2s 172us/step - loss: 0.0040 - acc: 0.9991 - val_loss: 1.3613 - val_acc: 0.7977\n",
      "Epoch 27/50\n",
      "10182/10182 [==============================] - 2s 163us/step - loss: 0.0070 - acc: 0.9982 - val_loss: 1.4140 - val_acc: 0.7906\n",
      "Epoch 28/50\n",
      "10182/10182 [==============================] - 2s 165us/step - loss: 0.0053 - acc: 0.9987 - val_loss: 1.3653 - val_acc: 0.7968\n",
      "Epoch 29/50\n",
      "10182/10182 [==============================] - 2s 163us/step - loss: 0.0061 - acc: 0.9986 - val_loss: 1.4067 - val_acc: 0.7986\n",
      "Epoch 30/50\n",
      "10182/10182 [==============================] - 2s 166us/step - loss: 0.0038 - acc: 0.9990 - val_loss: 1.3743 - val_acc: 0.7951\n",
      "Epoch 31/50\n",
      "10182/10182 [==============================] - 2s 166us/step - loss: 0.0071 - acc: 0.9986 - val_loss: 1.3602 - val_acc: 0.7933\n",
      "Epoch 32/50\n",
      "10182/10182 [==============================] - 2s 164us/step - loss: 0.0062 - acc: 0.9983 - val_loss: 1.3672 - val_acc: 0.7915\n",
      "Epoch 33/50\n",
      "10182/10182 [==============================] - 2s 166us/step - loss: 0.0059 - acc: 0.9987 - val_loss: 1.3697 - val_acc: 0.7942\n",
      "Epoch 34/50\n",
      "10182/10182 [==============================] - 2s 170us/step - loss: 0.0086 - acc: 0.9970 - val_loss: 1.3862 - val_acc: 0.8012\n",
      "Epoch 35/50\n",
      "10182/10182 [==============================] - 2s 171us/step - loss: 0.0079 - acc: 0.9978 - val_loss: 1.3751 - val_acc: 0.7924\n",
      "Epoch 36/50\n",
      "10182/10182 [==============================] - 2s 166us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 1.3564 - val_acc: 0.7995\n",
      "Epoch 37/50\n",
      "10182/10182 [==============================] - 2s 167us/step - loss: 0.0074 - acc: 0.9978 - val_loss: 1.3910 - val_acc: 0.7977\n",
      "Epoch 38/50\n",
      "10182/10182 [==============================] - 2s 167us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 1.4097 - val_acc: 0.7951\n",
      "Epoch 39/50\n",
      "10182/10182 [==============================] - 2s 164us/step - loss: 0.0091 - acc: 0.9981 - val_loss: 1.3503 - val_acc: 0.7959\n",
      "Epoch 40/50\n",
      "10182/10182 [==============================] - 2s 165us/step - loss: 0.0072 - acc: 0.9974 - val_loss: 1.3980 - val_acc: 0.7959\n",
      "Epoch 41/50\n",
      "10182/10182 [==============================] - 2s 189us/step - loss: 0.0210 - acc: 0.9948 - val_loss: 1.4677 - val_acc: 0.7853\n",
      "Epoch 42/50\n",
      "10182/10182 [==============================] - 2s 184us/step - loss: 0.0208 - acc: 0.9950 - val_loss: 1.4154 - val_acc: 0.7924\n",
      "Epoch 43/50\n",
      "10182/10182 [==============================] - 2s 187us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 1.4265 - val_acc: 0.7959\n",
      "Epoch 44/50\n",
      "10182/10182 [==============================] - 2s 186us/step - loss: 0.0105 - acc: 0.9973 - val_loss: 1.4339 - val_acc: 0.7968\n",
      "Epoch 45/50\n",
      "10182/10182 [==============================] - 2s 185us/step - loss: 0.0098 - acc: 0.9978 - val_loss: 1.4912 - val_acc: 0.7898\n",
      "Epoch 46/50\n",
      "10182/10182 [==============================] - 2s 179us/step - loss: 0.0108 - acc: 0.9974 - val_loss: 1.4414 - val_acc: 0.7889\n",
      "Epoch 47/50\n",
      "10182/10182 [==============================] - 2s 186us/step - loss: 0.0133 - acc: 0.9963 - val_loss: 1.4478 - val_acc: 0.7933\n",
      "Epoch 48/50\n",
      "10182/10182 [==============================] - 2s 183us/step - loss: 0.0100 - acc: 0.9970 - val_loss: 1.4672 - val_acc: 0.7968\n",
      "Epoch 49/50\n",
      "10182/10182 [==============================] - 2s 184us/step - loss: 0.0062 - acc: 0.9981 - val_loss: 1.4094 - val_acc: 0.7933\n",
      "Epoch 50/50\n",
      "10182/10182 [==============================] - 2s 186us/step - loss: 0.0068 - acc: 0.9978 - val_loss: 1.4418 - val_acc: 0.7959\n",
      "CPU times: user 3min 39s, sys: 20.5 s, total: 3min 59s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.callbacks import EarlyStopping  \n",
    "early_stopping=EarlyStopping(monitor='value_loss')  \n",
    "\n",
    "batch_size=100 #100 объектов на 1 эпоху а не вся обучающая выборка\n",
    "epochs=50      #кол-во эпох (сколько раз 100 объектов будут поданы сети)\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532/7532 [==============================] - 0s 51us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.696571743494643, 0.6534784905972534]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Точность на отложенной выборке\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранная остановка вывод: По времени выйгрыш не большой но есть и по качеству тоже небольшой прирост"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
